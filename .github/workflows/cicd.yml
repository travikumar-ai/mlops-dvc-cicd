# .github/workflows/cicd.yml

name: MLOps CI/CD Pipeline

on:
  push:
    branches:
      - main # Or your default branch

jobs:
  train-and-commit:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          # We need to fetch all branches and history so that DVC can push
          # changes back to the repository.
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13' # Match your project's Python version

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt # Assuming you have a requirements.txt file

      - name: Set up DVC
        uses: iterative/setup-dvc@v1

      - name: Configure DVC and Git
        # This step configures DVC to use your remote storage (like S3, GCS, or DagsHub storage)
        # and sets up Git user for committing back dvc.lock file.
        env:
          # Add these as secrets in your GitHub repository settings
          # (Settings -> Secrets and variables -> Actions)
          DAGSHUB_USER_NAME: ${{ secrets.DAGSHUB_USER_NAME }}
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          # dvc remote modify dagshub --local auth basic
          # dvc remote modify dagshub --local user 
          # dvc remote modify dagshub --local password 
          
          dvc remote add -f dagshub s3://mlops-dvc-cicd
          dvc remote modify dagshub endpointurl https://dagshub.com/api/v1/repo-buckets/s3/${{ env.DAGSHUB_USER_NAME }}
          dvc remote modify dagshub --local access_key_id $DAGSHUB_USER_NAME
          dvc remote modify dagshub --local secret_access_key $DAGSHUB_TOKEN
          
          # Configure Git user
          git config --global user.email "thotakuriravi@gmail.com"
          git config --global user.name "Ravi Kumar"

      - name: Pull Data and Models with DVC
        run: dvc pull

      - name: Run MLOps Pipeline
        env:
          # MLflow needs these to connect to DagsHub
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USER_NAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          # Run each stage of your pipeline
          # python src/components/data_ingestion.py
          # python src/components/data_transformation.py
          # python src/components/model_training.py

      - name: Push Artifacts to DVC Remote
        run: |
          # Add any new or changed artifacts to DVC tracking
          dvc add artifacts/preprocessor.pkl artifacts/models/
          dvc push
          
          # Commit and push dvc.lock and .dvc files
          git add artifacts/preprocessor.pkl.dvc artifacts/models.dvc .gitignore
          git diff --cached --quiet || git commit -m "CI/CD: Update data and models"
          git push
